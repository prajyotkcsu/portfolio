# Software Engineer

### Tech Stack: Java, Spring Boot, REST API, Kubernetes, Docker, AWS, Flink, Kafka, Elasticsearch, Airflow

### Education
- M.S. Business Analytics | California State University, East Bay (May 2023)
- B.S. Information Technology | Mumbai University (May 2017)

### Work Experience
**Software Engineer @ Dish Network (March 2024 - Present)**
I'm a developer on the 'Events' team and we handle communication on behalf of teams that wish to send messages to other teams. We refer these messages as events, ans so the team name as Events team.
Messages look some what like this




Below are some of the cool stuff that I've done so far being on the team.
- Built an API to delay message delivery by creating programmatic schedulers in AWS Schedule that sends messages to target teams only when the scheduler expire. This AWS component was never used before and was implemented and put into production for the first time. Mission accomplished and received applause from the rest of the team and the Engineering manager for my efforts behind a week long R&D to come up with this. We cutely named in 'The timer solution' that now other teams have adopted. 
- Enhanced platform storage by introducing AWS DynamoDB, enabling high query volumes and supporting key features like automatic archival and Capture Data Change with DynamoDB Streams.
- Engineered Apache Kafka infrastructure and servers to stream messages from various sources with 12% reduced cost.
- Improved developer experience by 35 % with gRPC, GraphQL APIs to expose backend databases, enhancing API reusability and speeding up preference retrieval with Redis caching.

**Software Engineer @ Financial Software & Systems (March 2018 - March 2021)**
- Built numerous features for a data platform that routes over 1M events daily, including mechanisms such as retry, replay, incident creation, and delay management, using Java Spring Boot and AWS Lambdas.
- Enhanced platform storage by introducing AWS DynamoDB, enabling high query volumes and supporting key features like automatic archival and Capture Data Change with DynamoDB Streams.
- Engineered Apache Kafka infrastructure and servers to stream messages from various sources with 12% reduced cost.
- Improved developer experience by 35 % with gRPC, GraphQL APIs to expose backend databases, enhancing API reusability and speeding up preference retrieval with Redis caching.
